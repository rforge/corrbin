%\VignetteIndexEntry{Using Oncotree for the ovarian cancer CGH data}
%\VignetteDepends{lattice}
\documentclass[reqno]{amsart}
\usepackage[margin=0.8in]{geometry}
\usepackage{graphicx}

\title{Using the CorrBin package for nonparametric analysis of correlated binary
data}
\author[A. Szabo]{Aniko Szabo}
\SweaveOpts{echo=TRUE}

\begin{document}
\setkeys{Gin}{width=0.5\textwidth}

\maketitle

\section{Overview}

The \texttt{CorrBin} package focuses on non-parametric methods for correlated binary
data with varying cluster sizes.
<<LibLoad>>=
  library(CorrBin)
@

\section{Data input}
All the analysis functions in the package work on \texttt{CBData} objects, so 
we start by setting up the data in the format needed for analysis. The Shell toxicology 
data set is available in the CBData format in the package, however we will load
it from a text file using the \texttt{read.CBData} function to show more typical usage. The
``ShellTox.txt'' file contains four space-delimited columns (other delimiters can also
be used). The first column contains an integer 1 -- 4 giving the treatment group, the second 
column gives the size of the cluster, the third the number of responses in the cluster, and the
last gives the number of times the given combination occured in the data.

<<Intro, echo=false>>=
 options(width=100)
 ps.options(colormodel="rgb")
<<DataLoad>>=
 sh <- read.CBData("ShellTox.txt", with.freq=TRUE)
 levels(sh$Trt) <- c("Control","Low","Medium", "High")
 str(sh)
@

Alternatively, if the data is already in a data frame, the \texttt{CBData} function
can be used to define the roles of the variables.

\section{Marginal compatibility}
A basic assumption of all of the following analyses is that of \emph{marginal compatibility} (MC),
which states that the size of the cluster has no effect on either the marginal probability of 
response, or the correlation (any order) within the cluster. Of course, this is only relevant if 
the clusters of different sizes are present in the data. We
can test for marginal compatibility:
<<MCtest>>=
  mc.test.chisq(sh)
@
Neither the overall p-value of 0.4, or the individual treatment group p-values show evidence
of deviation from marginal compatibility.

Now we can obtain non-parametric estimates of the distribution of the number of 
responses in the cluster under MC:
<<MCest>>=
  sh.mc <- mc.est(sh)
@ 
The \texttt{mc.est} functions gives estimates for all cluster-sizes, due to the 
marginal compatibility assumption the estimates $\pi_{r,M}$ for the largest cluster-size $M$
determine all the other estimates:
\begin{equation}
\pi_{r,n}  = \sum_{t=0}^{M}h(r,t,n)\pi_{t,M},
\end{equation}
where $h(r, t, n) = \binom{t}{r}\binom{M-t}{n-r}/\binom{M}{n}$ is the hypergeometric density function.
Figure~\ref{F:MCest} shows the estimates. 
\begin{figure}
<<MCestfig, fig=true, width=8, height=6>>=
  require(lattice)
  print(xyplot(Prob~NResp|factor(ClusterSize), groups=Trt, data=sh.mc, subset=ClusterSize>0 & ClusterSize<13, 
    type="l", as.table=TRUE, auto.key=list(columns=4, lines=TRUE, points=FALSE),
    xlab="Number of responses", ylab="P(R=r|N=n)"))
@
\caption{Density function of number of responses under MC by cluster-size estimated separately
for each treatment group}\label{F:MCest}
\end{figure}

The density functions in Figure~\ref{F:MCest} are difficult to compare (there is no
obvious shift); distribution functions often provide a cleaner comparison, so
they are plotted in Figure~\ref{F:MCsurvest}. These plots show that curves for the ``Control'' and
``Low'' groups tend to be above the ``Medium'' and ``High'' group, suggesting the 
presence of a dose related trend.
\begin{figure}
<<MCsurvfig, fig=true, width=8, height=6>>=
  panel.cumsum <- function(x,y,...){
    x.ord <- order(x)
    panel.xyplot(x[x.ord], cumsum(y[x.ord]), ...)}

   print(xyplot(Prob~NResp|factor(ClusterSize), groups=Trt, data=sh.mc, 
       subset=ClusterSize>0&ClusterSize<13, type="s",
       panel=panel.superpose, panel.groups=panel.cumsum,
       as.table=T, auto.key=list(columns=4, lines=T, points=F),
			 xlab="Number of responses", ylab="Cumulative Probability R(R>=r|N=n)",
			 ylim=c(0,1.1)))
@
\caption{Distribution functions of number of responses under MC by cluster-size estimated separately
for each treatment group}\label{F:MCsurvest}
\end{figure}

\section{Testing for trend}

Several methods have been proposed for testing for trend with correlated binary data; this
package implements 3 types of tests: the Rao-Scott (RS) test, 3 versions of a GEE-based test\footnote{The GEE approach is implemented,
even though it is not quite a non-parametric test}, and a stochastic
ordering (SO) based test. RS and GEE test for linear trend in the marginal probability of response, while SO tests for ordering of the distribution functions (as in Figure~\ref{F:MCsurvest}) of the number of responses..

The common interface for accessing the trend tests is the \texttt{trend.test} function. 
It allows to pick the test, whether a permutation-test based exact or an asymptotic (only for RS and GEE)
p-value should be used, and set algorithm options for the SO test. In this vignette we use $R=100$ permutations
to limit running time, but in actual work larger values should be used.

<<SOtest>>=
  set.seed(4461)
 (so.res <- trend.test(sh, test="SO", R=100, control=soControl(eps=0.1, max.directions=40)))
@
The \texttt{eps} parameter sets the limit on the absolute error of the log-likelihood (and thus, the
test statistic), while \texttt{max.directions} is a tuning parameter for the default ISDM algorithm: it
affects only the running time, and, in general, larger values lead to fewer iterations that however take
longer. The details of the permutation test are saved in the output object, so the null distribution of
the test statistic can be extracted for, say, a plot as in Figure~\ref{F:SOboot}.

\begin{figure}
<<SOboot>>=
 hist(attr(so.res, "boot")$t[,1], freq=FALSE, xlab="Statistic", ylab="Density", main="Null distribution of the SO test statistic")
 points(so.res$statistic, 0, pch="*",col="red", cex=3)
@
\caption{}\label{F:SOboot}
\end{figure}

The other tests also show the presence of a statistically significant trend:
<<RSGEEtest>>=
  trend.test(sh, test="RS")
  trend.test(sh, test="GEE")
@

The stochastic ordering approach provides not only a test for trend, but also the estimated distribution
of the number of responses under the alternative hypothesis of stochastic order. These can be obtained by the
\texttt{SO.mc.est} function:
<<SOmle>>=
   sh.SO.est <- SO.mc.est(sh, control=soControl(eps=0.1, max.directions=40))
@
\begin{figure}
<<SOmleplot, fig=true, width=8, height=6>>=
   print(xyplot(Prob~NResp|factor(ClusterSize), groups=Trt, data=sh.SO.est, 
       subset=ClusterSize,13, type="s",
       panel=panel.superpose, panel.groups=panel.cumsum,
       as.table=T, auto.key=list(columns=4, lines=T, points=F),
			 xlab="Number of responses", ylab="Cumulative Probability R(R>=r|N=n)",
			 ylim=c(0,1.1), main="Stochastically ordered estimates\n with marginal compatibility"))
@
\caption{Stochastically ordered distribution functions of the number of responses under MC by cluster-size.}\label{F:MCsurvest}
\end{figure}



\section{Risk assessment}

\end{document}

setwd("c:/RForge/CorrBin/inst/doc")
library(CorrBin)
Sweave("CorrBinVignette.Rnw", stylepath=FALSE)

